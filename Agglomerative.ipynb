{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarathSabu/SarathSabu/blob/main/Agglomerative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUdNp-8KOWUU"
      },
      "outputs": [],
      "source": [
        "# For Google Colab integration\n",
        "import os\n",
        "from google.colab import drive\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# For data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "##install the pywaffle package for visualization\n",
        "!pip install pywaffle matplotlib\n",
        "from pywaffle import Waffle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import data as dataframe\n",
        "file_path = '/content/drive/MyDrive/Infor648/Data/Mall_Customers.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# calling head() method\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MwKNJXOjO0xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select variables of interest"
      ],
      "metadata": {
        "id": "gNYq9uE2ShcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub= df[['Annual Income (k$)', 'Spending Score (1-100)']]"
      ],
      "metadata": {
        "id": "nZtW2CI_PbVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalize the data (or Standardize if needed)"
      ],
      "metadata": {
        "id": "uFtfaiNCSskP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# data normalization\n",
        "norm_scaler = MinMaxScaler()\n",
        "data_norm = norm_scaler.fit_transform(df_sub)\n",
        "##data_norm is the normalized data\n"
      ],
      "metadata": {
        "id": "cg9cji87PT4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Look for the largest vertical gap as this indicates a significant increase in dissimilarity between clusters.\n",
        "#Cut before the large vertical gap to avoid merging clusters that are too dissimilar and should remain separate."
      ],
      "metadata": {
        "id": "BPkJ3BC_UZhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#View it in Dendrogram"
      ],
      "metadata": {
        "id": "v2K3YGotg60Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "linked = linkage(data_norm, 'single')\n",
        "\n",
        "\n",
        "dendrogram(linked,\n",
        "           orientation='top',\n",
        "           show_leaf_counts=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7V1hCGyZPfLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "linked = linkage(data_norm, 'complete')\n",
        "\n",
        "\n",
        "dendrogram(linked,\n",
        "           orientation='top',\n",
        "           show_leaf_counts=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "obibR0jeWZoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "linked = linkage(data_norm, 'average')\n",
        "\n",
        "\n",
        "dendrogram(linked,\n",
        "           orientation='top',\n",
        "           show_leaf_counts=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dcp9lzfmW6uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate Silhouette score"
      ],
      "metadata": {
        "id": "IkAzWfIahAs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "range_n_clusters = list(range(2, 10))  #You can adjust the number here for the range you want to test\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Fit Agglomerative Clustering\n",
        "    agglom = AgglomerativeClustering(n_clusters=n_clusters, linkage='single')\n",
        "    cluster_labels = agglom.fit_predict(data_norm)\n",
        "\n",
        "    # Calculate silhouette score\n",
        "    silhouette_avg = silhouette_score(data_norm, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Plot silhouette scores for different cluster numbers\n",
        "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.title(\"Silhouette Scores for Single Agglomerative Clustering\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "OebNHVWkWqG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "range_n_clusters = list(range(2, 10))  #You can adjust the number here for the range you want to test\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Fit Agglomerative Clustering\n",
        "    agglom = AgglomerativeClustering(n_clusters=n_clusters, linkage='complete')\n",
        "    cluster_labels = agglom.fit_predict(data_norm)\n",
        "\n",
        "    # Calculate silhouette score\n",
        "    silhouette_avg = silhouette_score(data_norm, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Plot silhouette scores for different cluster numbers\n",
        "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.title(\"Silhouette Scores for Complete Agglomerative Clustering\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zLqv1eh0Ylqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "range_n_clusters = list(range(2, 10))  #You can adjust the number here for the range you want to test\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Fit Agglomerative Clustering\n",
        "    agglom = AgglomerativeClustering(n_clusters=n_clusters, linkage='average')\n",
        "    cluster_labels = agglom.fit_predict(data_norm)\n",
        "\n",
        "    # Calculate silhouette score\n",
        "    silhouette_avg = silhouette_score(data_norm, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Plot silhouette scores for different cluster numbers\n",
        "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.title(\"Silhouette Scores for Average Agglomerative Clustering\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ITyN5J__Y35h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Apply Agglomerative cluster"
      ],
      "metadata": {
        "id": "DqzuN8pchG22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Agglomerative Clustering\n",
        "AGNES_MIN= AgglomerativeClustering(n_clusters=2, metric='euclidean', linkage='single') ###adjust your number of clusters\n",
        "df_min = df_sub.copy()\n",
        "df_min['cluster'] = AGNES_MIN.fit_predict(data_norm)\n",
        "\n"
      ],
      "metadata": {
        "id": "LcollrE4P5DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot clusters\n",
        "unique_clusters = np.unique(df_min['cluster'])  # Find unique cluster labels\n",
        "colors = plt.cm.get_cmap('plasma', len(unique_clusters))\n",
        "\n",
        "for cluster_id in unique_clusters:\n",
        "    plt.scatter(data_norm[df_min['cluster'] == cluster_id, 0],\n",
        "                data_norm[df_min['cluster'] == cluster_id, 1],\n",
        "                s=100, c=[colors(cluster_id)], label=f'Cluster {cluster_id}')\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Agglomerative Clustering (Single Linkage) - Cluster Visualization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LJgOPgDNaf5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Agglomerative Clustering\n",
        "AGNES_AVG= AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='average')####Adjust your number of clusters\n",
        "df_avg = df_sub.copy()\n",
        "df_avg['cluster'] = AGNES_AVG.fit_predict(data_norm)"
      ],
      "metadata": {
        "id": "Wlz4rwBDbLcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot clusters\n",
        "unique_clusters = np.unique(df_avg['cluster'])  # Find unique cluster labels\n",
        "colors = plt.cm.get_cmap('plasma', len(unique_clusters))\n",
        "\n",
        "for cluster_id in unique_clusters:\n",
        "    plt.scatter(data_norm[df_avg['cluster'] == cluster_id, 0],\n",
        "                data_norm[df_avg['cluster'] == cluster_id, 1],\n",
        "                s=100, c=[colors(cluster_id)], label=f'Cluster {cluster_id}')\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Agglomerative Clustering (Average Linkage) - Cluster Visualization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i4n45pyWc8dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Agglomerative Clustering\n",
        "AGNES_MAX= AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='complete') ###adjust your number of clusters\n",
        "df_max = df_sub.copy()\n",
        "df_max['cluster'] = AGNES_MAX.fit_predict(data_norm)"
      ],
      "metadata": {
        "id": "k3X3Hf_AdLmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot clusters\n",
        "unique_clusters = np.unique(df_max['cluster'])  # Find unique cluster labels\n",
        "colors = plt.cm.get_cmap('plasma', len(unique_clusters))\n",
        "\n",
        "for cluster_id in unique_clusters:\n",
        "    plt.scatter(data_norm[df_max['cluster'] == cluster_id, 0],\n",
        "                data_norm[df_max['cluster'] == cluster_id, 1],\n",
        "                s=100, c=[colors(cluster_id)], label=f'Cluster {cluster_id}')\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Agglomerative Clustering (Complete Linkage) - Cluster Visualization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o-ca0Mpldbj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhouette score and silhouette samples\n",
        "silhouette_avg_min = silhouette_score(data_norm, df_min['cluster'])\n",
        "sample_silhouette_values_min = silhouette_samples(data_norm, df_min['cluster'])\n",
        "\n",
        "# Print the average silhouette score\n",
        "print(f\"Average silhouette score for Single Linkage: {silhouette_avg_min}\")\n",
        "\n",
        "\n",
        "# Optionally, you can print silhouette samples\n",
        "#print(\"Sample silhouette values:\")\n",
        "#print(sample_silhouette_values_min)"
      ],
      "metadata": {
        "id": "M_Np5-eKfetH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhouette score and silhouette samples\n",
        "silhouette_avg_max = silhouette_score(data_norm, df_max['cluster'])\n",
        "sample_silhouette_values_max = silhouette_samples(data_norm, df_max['cluster'])\n",
        "\n",
        "# Print the average silhouette score\n",
        "print(f\"Average silhouette score for complete linkage: {silhouette_avg_max }\")\n",
        "\n",
        "# Optionally, you can print silhouette samples\n",
        "#print(\"Sample silhouette values:\")\n",
        "#print(sample_silhouette_values_max)"
      ],
      "metadata": {
        "id": "JmYSY0Gwfgfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhouette score and silhouette samples\n",
        "silhouette_avg_avg = silhouette_score(data_norm, df_avg['cluster'])\n",
        "sample_silhouette_values_avg = silhouette_samples(data_norm, df_avg['cluster'])\n",
        "\n",
        "# Print the average silhouette score\n",
        "print(f\"Average silhouette score for average linkage: {silhouette_avg_avg}\")\n",
        "\n",
        "# Optionally, you can print or explore silhouette samples\n",
        "#print(\"Sample silhouette values:\")\n",
        "#print(sample_silhouette_values_avg)"
      ],
      "metadata": {
        "id": "J3Pq4aFoeIZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We need to understand the detailed stats inside each cluster"
      ],
      "metadata": {
        "id": "HpLQetcUmW0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##You do not need to change anything here! but if you do not like the color you can change the color here\n",
        "def generate_cluster_profile_agnes(data_norm, k, df_original, metrics_select, linkage_used):\n",
        "\n",
        "    # Apply AgglomerativeClustering (AGNES) with customizable metrics and linkage\n",
        "    agnes_stats = AgglomerativeClustering(n_clusters=k, metric=metrics_select, linkage=linkage_used)\n",
        "    df_sub = df_original.copy()\n",
        "    df_sub['cluster'] = agnes_stats.fit_predict(data_norm)\n",
        "\n",
        "    # Create a copy of the DataFrame for calculations\n",
        "    df_calculate = df_sub.copy()\n",
        "    df_calculate['cluster_result'] = 'Cluster ' + (df_calculate['cluster']).astype(str)\n",
        "\n",
        "    # Exclude the 'cluster' column for mean calculation\n",
        "    df_mean_calculation = df_calculate.drop(columns=['cluster'])\n",
        "    df_mean_feature = df_mean_calculation.drop(columns=['cluster_result'])  # Exclude 'cluster_result' column for overall mean\n",
        "\n",
        "    # Calculate Overall Mean for All Features in df_mean_feature\n",
        "    overall_means = df_mean_feature.mean().to_frame().T\n",
        "    overall_means.index = ['Overall']\n",
        "\n",
        "    # Summarize Mean of Each Cluster\n",
        "    df_cluster_summary = df_mean_calculation.groupby('cluster_result').mean()\n",
        "\n",
        "    # Add Overall Mean Row to Cluster Summary\n",
        "    df_profile = pd.concat([df_cluster_summary, overall_means], axis=0)\n",
        "\n",
        "    # Calculate the count of items in each cluster\n",
        "    cluster_counts = df_calculate['cluster_result'].value_counts()\n",
        "\n",
        "    # Calculate the percentage of items in each cluster\n",
        "    cluster_percentages = (cluster_counts / cluster_counts.sum()) * 100\n",
        "\n",
        "    # Create a DataFrame with counts and percentages\n",
        "    df_count_percentage = pd.DataFrame({\n",
        "        'Count': cluster_counts,\n",
        "        'Percentage': cluster_percentages\n",
        "    })\n",
        "\n",
        "    # Add a row for \"Overall\"\n",
        "    df_count_percentage.loc['Overall'] = [len(df_calculate), 100.0]\n",
        "    df_profile = pd.concat([df_profile, df_count_percentage], axis=1)\n",
        "    df_overall = df_profile.loc['Overall']\n",
        "    df_profile = df_profile.drop(index='Overall')\n",
        "\n",
        "    # Sort the clusters by the Count column\n",
        "    df_profile = df_profile.sort_values(by='Count', ascending=False)\n",
        "\n",
        "    # Append the \"Overall\" row back to the sorted DataFrame\n",
        "    df_profile = pd.concat([df_profile, df_overall.to_frame().T])\n",
        "\n",
        "    # Format the profile DataFrame\n",
        "    df_profile = df_profile.style.format({\n",
        "        \"Count\": \"{:.0f}\",\n",
        "        **{col: \"{:.2f}\" for col in df_profile.columns if col != \"Count\"}  # Two decimal places for all other columns\n",
        "    }).background_gradient(cmap='Purples') ######Change colore here you can use Blues Purples, Oranges, Reds, Greens, Greys\n",
        "\n",
        "    return df_profile\n",
        "\n"
      ],
      "metadata": {
        "id": "W3UkCd9_gk2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Single linkage cluster stats\n",
        "df_profile_min = generate_cluster_profile_agnes(data_norm, k=2, df_original=df_sub, metrics_select='euclidean', linkage_used='single')\n",
        "display(df_profile_min)\n",
        "print()\n",
        "\n",
        "##Average linkage cluster stats\n",
        "df_profile_avg = generate_cluster_profile_agnes(data_norm, k=5, df_original=df_sub, metrics_select='euclidean', linkage_used='average')\n",
        "display(df_profile_avg)\n",
        "print()\n",
        "\n",
        "##Complete linkage cluster stats\n",
        "df_profile_max = generate_cluster_profile_agnes(data_norm, k=5, df_original=df_sub, metrics_select='euclidean', linkage_used='complete')\n",
        "display(df_profile_max)\n",
        "print()"
      ],
      "metadata": {
        "id": "be6QlSPXigmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pywaffle import Waffle\n",
        "\n",
        "\n",
        "cluster_counts = df_min['cluster'].value_counts()\n",
        "total = sum(cluster_counts)\n",
        "\n",
        "# Plot the waffle chart with percentages added to the labels\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,  # Number of rows in the waffle chart, you can adjust here\n",
        "    values=cluster_counts,  # Values for each cluster\n",
        "    title={'label': 'Cluster Distribution for Single Linkage', 'loc': 'center'},\n",
        "    labels=[f\"Cluster {i} ({count} - {round((count / total) * 100, 2)}%)\" for i, count in cluster_counts.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1.2)}, #You can also adjust the number to adjust the legend location\n",
        "    figsize=(8, 5) #adjust figure size\n",
        ")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DwPOsaTUlmjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_counts = df_avg['cluster'].value_counts()\n",
        "total = sum(cluster_counts)\n",
        "\n",
        "# Plot the waffle chart with percentages added to the labels\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,  # Number of rows in the waffle chart, you can adjust here\n",
        "    values=cluster_counts,  # Values for each cluster\n",
        "    title={'label': 'Cluster Distribution for Average Linkage', 'loc': 'center'},\n",
        "    labels=[f\"Cluster {i} ({count} - {round((count / total) * 100, 2)}%)\" for i, count in cluster_counts.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1.2)}, # You can also change the number to adjust the legend location\n",
        "    figsize=(8, 5) #adjust figure size\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EIWrbS3FnhhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_counts = df_max['cluster'].value_counts()\n",
        "total = sum(cluster_counts)\n",
        "\n",
        "# Plot the waffle chart with percentages added to the labels\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,  # Number of rows in the waffle chart, you can adjust here\n",
        "    values=cluster_counts,  # Values for each cluster\n",
        "    title={'label': 'Cluster Distribution for Average Linkage', 'loc': 'center'},\n",
        "    labels=[f\"Cluster {i} ({count} - {round((count / total) * 100, 2)}%)\" for i, count in cluster_counts.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1.2)}, #You can also adjust the number to adjust the legend location\n",
        "    figsize=(8, 5) #adjust figure size\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K4mh2r5un55s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}